#!/usr/bin/env python3
"""
Google Sheets é›†æˆ
è‡ªåŠ¨å°†æ•°æ®å¯¼å‡ºåˆ° Google Sheets
"""
import gspread
from google.oauth2.service_account import Credentials
import pandas as pd
from datetime import datetime, timedelta
import yaml
import os
import json

# Google Sheets API æƒé™èŒƒå›´
SCOPES = [
    'https://www.googleapis.com/auth/spreadsheets',
    'https://www.googleapis.com/auth/drive'
]

def get_sheets_client(credentials_path: str = None):
    """
    è·å– Google Sheets å®¢æˆ·ç«¯
    
    æ”¯æŒå¤šç§å‡­è¯æ¥æºï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. Streamlit Secretsï¼ˆå¦‚æœåœ¨ Streamlit ç¯å¢ƒä¸­ï¼‰
    2. ç¯å¢ƒå˜é‡ GOOGLE_CREDENTIALS_JSONï¼ˆJSON å­—ç¬¦ä¸²ï¼‰
    3. æœ¬åœ°æ–‡ä»¶ google_credentials.json
    """
    creds = None
    
    # æ–¹å¼ 1: å°è¯•ä» Streamlit Secrets è¯»å–ï¼ˆä»…åœ¨ Streamlit ç¯å¢ƒä¸­ï¼‰
    try:
        import streamlit as st
        # åœ¨ Streamlit ç¯å¢ƒä¸­ï¼Œç›´æ¥æ£€æŸ¥ secrets
        if hasattr(st, 'secrets'):
            try:
                if 'google_sheets' in st.secrets:
                    creds_dict = st.secrets['google_sheets'].get('credentials')
                    if creds_dict:
                        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ JSON
                        if isinstance(creds_dict, str):
                            creds_dict = json.loads(creds_dict)
                        elif isinstance(creds_dict, dict):
                            # å·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
                            pass
                        else:
                            creds_dict = None
                        
                        if creds_dict:
                            creds = Credentials.from_service_account_info(creds_dict, scopes=SCOPES)
                            return gspread.authorize(creds)
            except (KeyError, AttributeError, json.JSONDecodeError) as e:
                # Secrets é…ç½®æœ‰é—®é¢˜ï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹å¼
                pass
    except (ImportError, FileNotFoundError):
        # ä¸åœ¨ Streamlit ç¯å¢ƒæˆ– secrets æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹å¼
        pass
    
    # æ–¹å¼ 2: å°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–ï¼ˆJSON å­—ç¬¦ä¸²ï¼‰
    creds_json = os.getenv("GOOGLE_CREDENTIALS_JSON")
    if creds_json:
        try:
            creds_dict = json.loads(creds_json)
            creds = Credentials.from_service_account_info(creds_dict, scopes=SCOPES)
            return gspread.authorize(creds)
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            print(f"âš ï¸ ç¯å¢ƒå˜é‡ GOOGLE_CREDENTIALS_JSON æ ¼å¼é”™è¯¯: {e}")
    
    # æ–¹å¼ 3: ä»æœ¬åœ°æ–‡ä»¶è¯»å–
    # å¦‚æœ credentials_path ä¸º Noneï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    if credentials_path is None:
        credentials_path = "google_credentials.json"
    
    if credentials_path and os.path.exists(credentials_path):
        creds = Credentials.from_service_account_file(credentials_path, scopes=SCOPES)
        return gspread.authorize(creds)
    
    # å¦‚æœæ‰€æœ‰æ–¹å¼éƒ½å¤±è´¥
    raise FileNotFoundError(
        f"Google å‡­è¯æœªæ‰¾åˆ°\n"
        "è¯·é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€ï¼š\n"
        "1. åœ¨ Streamlit Secrets ä¸­é…ç½® google_sheets.credentials\n"
        "2. è®¾ç½®ç¯å¢ƒå˜é‡ GOOGLE_CREDENTIALS_JSON\n"
        "3. åˆ›å»ºæ–‡ä»¶ google_credentials.json"
    )

def export_to_sheets(df: pd.DataFrame, spreadsheet_id: str, sheet_name: str = None, 
                     credentials_path: str = None):
    """
    å¯¼å‡º DataFrame åˆ° Google Sheets
    
    Args:
        df: è¦å¯¼å‡ºçš„ DataFrame
        spreadsheet_id: Google Sheets çš„ IDï¼ˆä» URL ä¸­è·å–ï¼‰
        sheet_name: Sheet åç§°ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™è¦†ç›–ç¬¬ä¸€ä¸ª sheetï¼‰
        credentials_path: Google å‡­è¯æ–‡ä»¶è·¯å¾„
    """
    client = get_sheets_client(credentials_path)
    
    # æ‰“å¼€ spreadsheet
    spreadsheet = client.open_by_key(spreadsheet_id)
    
    # é€‰æ‹©æˆ–åˆ›å»º sheet
    if sheet_name:
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
        except gspread.exceptions.WorksheetNotFound:
            worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=10)
    else:
        worksheet = spreadsheet.sheet1
    
    # æ¸…ç©ºç°æœ‰æ•°æ®ï¼ˆä¿ç•™æ ‡é¢˜è¡Œï¼‰
    worksheet.clear()
    
    # å†™å…¥æ•°æ®
    # å…ˆå†™å…¥åˆ—å
    worksheet.append_row(df.columns.tolist())
    
    # å†™å…¥æ•°æ®ï¼ˆåˆ†æ‰¹å†™å…¥ï¼Œé¿å…è¶…æ—¶ï¼‰
    batch_size = 100
    for i in range(0, len(df), batch_size):
        batch = df.iloc[i:i+batch_size]
        values = batch.values.tolist()
        worksheet.append_rows(values)
    
    print(f"âœ… å·²å¯¼å‡º {len(df)} è¡Œæ•°æ®åˆ° Google Sheets: {sheet_name}")

def export_to_sheets_append(df: pd.DataFrame, spreadsheet_id: str, sheet_name: str = None, 
                            credentials_path: str = None, sort_by_date: bool = True):
    """
    è¿½åŠ  DataFrame åˆ° Google Sheetsï¼ˆè·¨ sheet å»é‡åè¿½åŠ ï¼Œå¹¶æŒ‰æ—¥æœŸæ’åºï¼‰
    
    Args:
        df: è¦è¿½åŠ çš„ DataFrame
        spreadsheet_id: Google Sheets çš„ ID
        sheet_name: Sheet åç§°
        credentials_path: Google å‡­è¯æ–‡ä»¶è·¯å¾„
        sort_by_date: æ˜¯å¦æŒ‰æ—¥æœŸæ’åºï¼ˆä»æ—©åˆ°æ™šï¼‰
    """
    client = get_sheets_client(credentials_path)
    spreadsheet = client.open_by_key(spreadsheet_id)
    
    # è·¨ sheet å»é‡ï¼šæ”¶é›†æ‰€æœ‰ sheet ä¸­çš„ URL
    all_existing_urls = set()
    if 'URL' in df.columns:
        for sheet in spreadsheet.worksheets():
            try:
                sheet_data = sheet.get_all_values()
                if len(sheet_data) > 1:
                    sheet_df = pd.DataFrame(sheet_data[1:], columns=sheet_data[0])
                    if 'URL' in sheet_df.columns:
                        all_existing_urls.update(sheet_df['URL'].dropna())
            except Exception as e:
                print(f"âš ï¸ è¯»å– sheet '{sheet.title}' æ—¶å‡ºé”™: {e}")
                continue
        
        # è¿‡æ»¤æ‰å·²å­˜åœ¨çš„ URL
        original_count = len(df)
        df = df[~df['URL'].isin(all_existing_urls)]
        if len(df) < original_count:
            print(f"ğŸ“ è·¨ sheet å»é‡ï¼šè¿‡æ»¤æ‰ {original_count - len(df)} ç¯‡å·²å­˜åœ¨çš„æ–‡ç« ")
    
    # é€‰æ‹©æˆ–åˆ›å»º sheet
    if sheet_name:
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
            # å¦‚æœ sheet å·²å­˜åœ¨ï¼Œè¯»å–ç°æœ‰æ•°æ®
            existing_data = worksheet.get_all_values()
            if len(existing_data) > 1:
                existing_df = pd.DataFrame(existing_data[1:], columns=existing_data[0])
                # åˆå¹¶ç°æœ‰æ•°æ®å’Œæ–°æ•°æ®
                combined_df = pd.concat([existing_df, df], ignore_index=True)
            else:
                # sheet å­˜åœ¨ä½†åªæœ‰æ ‡é¢˜è¡Œï¼Œç›´æ¥ä½¿ç”¨æ–°æ•°æ®
                combined_df = df.copy()
        except gspread.exceptions.WorksheetNotFound:
            worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=10)
            # æ–° sheetï¼Œç›´æ¥ä½¿ç”¨æ–°æ•°æ®
            combined_df = df.copy()
            existing_data = []  # æ–° sheetï¼Œæ²¡æœ‰ç°æœ‰æ•°æ®
    else:
        worksheet = spreadsheet.sheet1
        existing_data = worksheet.get_all_values()
        if len(existing_data) > 1:
            existing_df = pd.DataFrame(existing_data[1:], columns=existing_data[0])
            combined_df = pd.concat([existing_df, df], ignore_index=True)
        else:
            combined_df = df.copy()
    
    # å¦‚æœæ²¡æœ‰æ–°æ•°æ®ï¼Œåªé‡æ–°æ’åº
    if df.empty:
        if len(existing_data) > 1:
            existing_df = pd.DataFrame(existing_data[1:], columns=existing_data[0])
            print(f"âš ï¸ æ‰€æœ‰æ•°æ®å·²å­˜åœ¨ï¼ˆè·¨ sheet å»é‡ï¼‰ï¼Œé‡æ–°æ’åºç°æœ‰æ•°æ®...")
            if sort_by_date and 'Date' in existing_df.columns:
                _sort_sheet_by_date(worksheet, existing_df, existing_data[0])
                print(f"âœ… å·²æŒ‰æ—¥æœŸæ’åºå®Œæˆ")
            return
        else:
            print(f"âš ï¸ æ²¡æœ‰æ–°æ•°æ®å¯è¿½åŠ ")
            return
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆä»æ—©åˆ°æ™šï¼‰
    if sort_by_date and 'Date' in combined_df.columns:
        try:
            # å°è¯•è§£ææ—¥æœŸ
            combined_df['Date_parsed'] = pd.to_datetime(combined_df['Date'], errors='coerce')
            # å…ˆæŒ‰æ—¥æœŸæ’åºï¼Œç„¶ååˆ é™¤ä¸´æ—¶åˆ—
            combined_df = combined_df.sort_values('Date_parsed', ascending=True, na_position='last')
            combined_df = combined_df.drop('Date_parsed', axis=1)
        except Exception as e:
            print(f"âš ï¸ æ—¥æœŸæ’åºå¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹é¡ºåº")
    
    # æ¸…ç©º sheet å¹¶é‡æ–°å†™å…¥ï¼ˆä¿ç•™æ ‡é¢˜è¡Œï¼‰
    worksheet.clear()
    if len(existing_data) > 0:
        worksheet.append_row(existing_data[0])  # å†™å…¥æ ‡é¢˜è¡Œ
    else:
        worksheet.append_row(combined_df.columns.tolist())
    
    # å†™å…¥æ•°æ®ï¼ˆåˆ†æ‰¹å†™å…¥ï¼‰
    if not combined_df.empty:
        batch_size = 100
        for i in range(0, len(combined_df), batch_size):
            batch = combined_df.iloc[i:i+batch_size]
            values = batch.values.tolist()
            worksheet.append_rows(values)
        
        new_count = len(df)
        total_count = len(combined_df)
        print(f"âœ… å·²è¿½åŠ  {new_count} è¡Œæ–°æ•°æ®ï¼Œæ€»è®¡ {total_count} è¡Œï¼ˆå·²æŒ‰æ—¥æœŸæ’åºï¼‰åˆ° Google Sheets: {sheet_name}")

def _sort_sheet_by_date(worksheet, df: pd.DataFrame, headers: list):
    """
    å¯¹ sheet æŒ‰æ—¥æœŸæ’åºï¼ˆè¾…åŠ©å‡½æ•°ï¼‰
    """
    try:
        # æŒ‰æ—¥æœŸæ’åº
        if 'Date' in df.columns:
            df['Date_parsed'] = pd.to_datetime(df['Date'], errors='coerce')
            df = df.sort_values('Date_parsed', ascending=True, na_position='last')
            df = df.drop('Date_parsed', axis=1)
        
        # æ¸…ç©ºå¹¶é‡æ–°å†™å…¥
        worksheet.clear()
        worksheet.append_row(headers)
        
        batch_size = 100
        for i in range(0, len(df), batch_size):
            batch = df.iloc[i:i+batch_size]
            values = batch.values.tolist()
            worksheet.append_rows(values)
    except Exception as e:
        print(f"âš ï¸ æ’åºå¤±è´¥: {e}")

def create_weekly_sheet(df: pd.DataFrame, spreadsheet_id: str, 
                        credentials_path: str = "google_credentials.json"):
    """
    åˆ›å»ºæ¯å‘¨çš„ sheetï¼ˆæŒ‰æ—¥æœŸå‘½åï¼‰
    """
    # è·å–æ—¥æœŸèŒƒå›´
    if 'Date' in df.columns:
        dates = pd.to_datetime(df['Date'], errors='coerce').dropna()
        if len(dates) > 0:
            start_date = dates.min().strftime("%Y-%m-%d")
            end_date = dates.max().strftime("%Y-%m-%d")
            sheet_name = f"Week {start_date} to {end_date}"
        else:
            sheet_name = f"Week {datetime.now().strftime('%Y-%m-%d')}"
    else:
        sheet_name = f"Week {datetime.now().strftime('%Y-%m-%d')}"
    
    export_to_sheets(df, spreadsheet_id, sheet_name, credentials_path)

def read_from_sheets(spreadsheet_id: str, sheet_name: str = None,
                    credentials_path: str = None) -> pd.DataFrame:
    """
    ä» Google Sheets è¯»å–æ•°æ®
    """
    client = get_sheets_client(credentials_path)
    spreadsheet = client.open_by_key(spreadsheet_id)
    
    if sheet_name:
        worksheet = spreadsheet.worksheet(sheet_name)
    else:
        worksheet = spreadsheet.sheet1
    
    # è¯»å–æ‰€æœ‰æ•°æ®
    data = worksheet.get_all_values()
    
    if len(data) == 0:
        return pd.DataFrame()
    
    # ç¬¬ä¸€è¡Œä½œä¸ºåˆ—å
    df = pd.DataFrame(data[1:], columns=data[0])
    return df

