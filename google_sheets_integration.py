#!/usr/bin/env python3
"""
Google Sheets é›†æˆ
è‡ªåŠ¨å°†æ•°æ®å¯¼å‡ºåˆ° Google Sheets
"""
import gspread
from google.oauth2.service_account import Credentials
import pandas as pd
from datetime import datetime, timedelta
import yaml
import os
import json

# Google Sheets API æƒé™èŒƒå›´
SCOPES = [
    'https://www.googleapis.com/auth/spreadsheets',
    'https://www.googleapis.com/auth/drive'
]

def get_sheets_client(credentials_path: str = None):
    """
    è·å– Google Sheets å®¢æˆ·ç«¯
    
    æ”¯æŒå¤šç§å‡­è¯æ¥æºï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. Streamlit Secretsï¼ˆå¦‚æœåœ¨ Streamlit ç¯å¢ƒä¸­ï¼‰
    2. ç¯å¢ƒå˜é‡ GOOGLE_CREDENTIALS_JSONï¼ˆJSON å­—ç¬¦ä¸²ï¼‰
    3. æœ¬åœ°æ–‡ä»¶ google_credentials.json
    """
    creds = None
    
    # æ–¹å¼ 1: å°è¯•ä» Streamlit Secrets è¯»å–ï¼ˆä»…åœ¨ Streamlit ç¯å¢ƒä¸­ï¼‰
    try:
        import streamlit as st
        # åœ¨ Streamlit ç¯å¢ƒä¸­ï¼Œç›´æ¥æ£€æŸ¥ secrets
        if hasattr(st, 'secrets'):
            try:
                if 'google_sheets' in st.secrets:
                    creds_dict = st.secrets['google_sheets'].get('credentials')
                    if creds_dict:
                        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ JSON
                        if isinstance(creds_dict, str):
                            creds_dict = json.loads(creds_dict)
                        elif isinstance(creds_dict, dict):
                            # å·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
                            pass
                        else:
                            creds_dict = None
                        
                        if creds_dict:
                            creds = Credentials.from_service_account_info(creds_dict, scopes=SCOPES)
                            return gspread.authorize(creds)
            except (KeyError, AttributeError, json.JSONDecodeError) as e:
                # Secrets é…ç½®æœ‰é—®é¢˜ï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹å¼
                pass
    except (ImportError, FileNotFoundError):
        # ä¸åœ¨ Streamlit ç¯å¢ƒæˆ– secrets æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹å¼
        pass
    
    # æ–¹å¼ 2: å°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–ï¼ˆJSON å­—ç¬¦ä¸²ï¼‰
    creds_json = os.getenv("GOOGLE_CREDENTIALS_JSON")
    if creds_json:
        try:
            creds_dict = json.loads(creds_json)
            creds = Credentials.from_service_account_info(creds_dict, scopes=SCOPES)
            return gspread.authorize(creds)
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            print(f"âš ï¸ ç¯å¢ƒå˜é‡ GOOGLE_CREDENTIALS_JSON æ ¼å¼é”™è¯¯: {e}")
    
    # æ–¹å¼ 3: ä»æœ¬åœ°æ–‡ä»¶è¯»å–
    # å¦‚æœ credentials_path ä¸º Noneï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    if credentials_path is None:
        credentials_path = "google_credentials.json"
    
    if credentials_path and os.path.exists(credentials_path):
        creds = Credentials.from_service_account_file(credentials_path, scopes=SCOPES)
        return gspread.authorize(creds)
    
    # å¦‚æœæ‰€æœ‰æ–¹å¼éƒ½å¤±è´¥
    raise FileNotFoundError(
        f"Google å‡­è¯æœªæ‰¾åˆ°\n"
        "è¯·é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€ï¼š\n"
        "1. åœ¨ Streamlit Secrets ä¸­é…ç½® google_sheets.credentials\n"
        "2. è®¾ç½®ç¯å¢ƒå˜é‡ GOOGLE_CREDENTIALS_JSON\n"
        "3. åˆ›å»ºæ–‡ä»¶ google_credentials.json"
    )

def export_to_sheets(df: pd.DataFrame, spreadsheet_id: str, sheet_name: str = None, 
                     credentials_path: str = None):
    """
    å¯¼å‡º DataFrame åˆ° Google Sheets
    
    Args:
        df: è¦å¯¼å‡ºçš„ DataFrame
        spreadsheet_id: Google Sheets çš„ IDï¼ˆä» URL ä¸­è·å–ï¼‰
        sheet_name: Sheet åç§°ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™è¦†ç›–ç¬¬ä¸€ä¸ª sheetï¼‰
        credentials_path: Google å‡­è¯æ–‡ä»¶è·¯å¾„
    """
    client = get_sheets_client(credentials_path)
    
    # æ‰“å¼€ spreadsheet
    spreadsheet = client.open_by_key(spreadsheet_id)
    
    # é€‰æ‹©æˆ–åˆ›å»º sheet
    if sheet_name:
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
        except gspread.exceptions.WorksheetNotFound:
            worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=10)
    else:
        worksheet = spreadsheet.sheet1
    
    # æ¸…ç©ºç°æœ‰æ•°æ®ï¼ˆä¿ç•™æ ‡é¢˜è¡Œï¼‰
    worksheet.clear()
    
    # å†™å…¥æ•°æ®
    # å…ˆå†™å…¥åˆ—å
    worksheet.append_row(df.columns.tolist())
    
    # å†™å…¥æ•°æ®ï¼ˆåˆ†æ‰¹å†™å…¥ï¼Œé¿å…è¶…æ—¶ï¼‰
    batch_size = 100
    for i in range(0, len(df), batch_size):
        batch = df.iloc[i:i+batch_size]
        values = batch.values.tolist()
        worksheet.append_rows(values)
    
    print(f"âœ… å·²å¯¼å‡º {len(df)} è¡Œæ•°æ®åˆ° Google Sheets: {sheet_name}")

def export_to_sheets_append(df: pd.DataFrame, spreadsheet_id: str, sheet_name: str = None, 
                            credentials_path: str = None, sort_by_date: bool = True):
    """
    è¿½åŠ  DataFrame åˆ° Google Sheetsï¼ˆæ–°é€»è¾‘ï¼šæ£€æŸ¥URL -> è¡¥å……æ–°æ•°æ® -> æ’åºï¼‰
    
    æµç¨‹ï¼š
    1. è·¨ sheet æ£€æŸ¥ URLï¼ˆå»é‡ï¼‰
    2. è¯»å–å½“å‰ sheet çš„ç°æœ‰æ•°æ®
    3. åˆå¹¶æ–°æ•°æ®ï¼ˆè¿‡æ»¤æ‰å·²å­˜åœ¨çš„ URLï¼‰
    4. å»é‡
    5. æ’åº
    6. é‡æ–°å†™å…¥ï¼ˆç¡®ä¿æ ‡é¢˜è¡Œå­˜åœ¨ï¼‰
    
    Args:
        df: è¦è¿½åŠ çš„ DataFrame
        spreadsheet_id: Google Sheets çš„ ID
        sheet_name: Sheet åç§°
        credentials_path: Google å‡­è¯æ–‡ä»¶è·¯å¾„
        sort_by_date: æ˜¯å¦æŒ‰æ—¥æœŸæ’åºï¼ˆä»æ—©åˆ°æ™šï¼‰
    """
    client = get_sheets_client(credentials_path)
    spreadsheet = client.open_by_key(spreadsheet_id)
    
    # ========== æ­¥éª¤1: è·¨ sheet æ£€æŸ¥ URLï¼ˆå»é‡ï¼‰ ==========
    all_existing_urls = set()
    if 'URL' in df.columns:
        for sheet in spreadsheet.worksheets():
            try:
                sheet_data = sheet.get_all_values()
                if len(sheet_data) <= 1:
                    continue
                if len(sheet_data[0]) == 0:
                    continue
                sheet_df = pd.DataFrame(sheet_data[1:], columns=sheet_data[0])
                if 'URL' not in sheet_df.columns:
                    continue
                urls = sheet_df['URL'].dropna()
                if len(urls) == 0:
                    continue
                # æ”¶é›†æ‰€æœ‰ sheet çš„ URLï¼ˆåŒ…æ‹¬å½“å‰ sheetï¼Œç”¨äºåç»­å»é‡ï¼‰
                all_existing_urls.update(urls)
            except Exception as e:
                print(f"âš ï¸ è¯»å– sheet '{sheet.title}' æ—¶å‡ºé”™: {e}")
                continue
        
        # è¿‡æ»¤æ‰æ‰€æœ‰ sheet ä¸­å·²å­˜åœ¨çš„ URL
        original_count = len(df)
        df = df[~df['URL'].astype(str).str.strip().isin([url.strip() for url in all_existing_urls])]
        if len(df) < original_count:
            print(f"ğŸ“ è·¨ sheet å»é‡ï¼šè¿‡æ»¤æ‰ {original_count - len(df)} ç¯‡å·²å­˜åœ¨çš„æ–‡ç« ")
    
    # ========== æ­¥éª¤2: é€‰æ‹©æˆ–åˆ›å»º sheet ==========
    if sheet_name:
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
            sheet_exists = True
        except gspread.exceptions.WorksheetNotFound:
            worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=10)
            sheet_exists = False
    else:
        worksheet = spreadsheet.sheet1
        sheet_exists = True
    
    # ========== æ­¥éª¤3: è¯»å–ç°æœ‰æ•°æ®å¹¶åˆå¹¶æ–°æ•°æ® ==========
    expected_columns = df.columns.tolist()
    existing_df = pd.DataFrame()
    
    # æ— è®ºæ˜¯æ–°sheetè¿˜æ˜¯å·²å­˜åœ¨çš„sheetï¼Œéƒ½å°è¯•è¯»å–æ•°æ®
    try:
        existing_data = worksheet.get_all_values()
        if len(existing_data) > 0:
            existing_headers = existing_data[0]
            
            # æ£€æŸ¥æ ‡é¢˜è¡Œæ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
            has_valid_header = (len(existing_headers) > 0 and 
                              any(str(h).strip() for h in existing_headers) and
                              len(set(str(h).strip() for h in existing_headers if h) & set(expected_columns)) >= 2)
            
            if has_valid_header:
                # æœ‰æœ‰æ•ˆçš„æ ‡é¢˜è¡Œï¼Œè¯»å–æ•°æ®ï¼ˆè·³è¿‡æ ‡é¢˜è¡Œï¼‰
                if len(existing_data) > 1:
                    existing_df = pd.DataFrame(existing_data[1:], columns=existing_headers)
                    # ç¡®ä¿åˆ—é¡ºåºä¸æœŸæœ›ä¸€è‡´
                    if set(existing_headers) == set(expected_columns):
                        existing_df = existing_df[expected_columns]
                    else:
                        # åˆ—åä¸å®Œå…¨åŒ¹é…ï¼Œå¯¹é½
                        aligned_df = pd.DataFrame()
                        for col in expected_columns:
                            if col in existing_headers:
                                aligned_df[col] = existing_df[col]
                            else:
                                aligned_df[col] = None
                        existing_df = aligned_df
                    print(f"ğŸ“– è¯»å–ç°æœ‰æ•°æ®: {len(existing_df)} è¡Œ")
                else:
                    # åªæœ‰æ ‡é¢˜è¡Œï¼Œæ²¡æœ‰æ•°æ®
                    print(f"â„¹ï¸ Sheet åªæœ‰æ ‡é¢˜è¡Œï¼Œæ²¡æœ‰æ•°æ®")
            else:
                # æ ‡é¢˜è¡Œæ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œç¬¬ä¸€è¡Œå¯èƒ½æ˜¯æ•°æ®
                if len(existing_data) > 0:
                    # ç¬¬ä¸€è¡Œå¯èƒ½æ˜¯æ•°æ®ï¼Œå…¨éƒ¨å½“ä½œæ•°æ®è¯»å–
                    existing_df = pd.DataFrame(existing_data, columns=expected_columns[:len(existing_data[0])] if existing_data else expected_columns)
                    # å¦‚æœåˆ—æ•°ä¸åŒ¹é…ï¼Œå°è¯•å¯¹é½
                    if len(existing_data[0]) != len(expected_columns):
                        aligned_df = pd.DataFrame()
                        for i, col in enumerate(expected_columns):
                            if i < len(existing_data[0]):
                                # ä»ç¬¬ä¸€è¡Œå¼€å§‹è¯»å–æ‰€æœ‰æ•°æ®
                                aligned_df[col] = [row[i] if i < len(row) else "" for row in existing_data]
                            else:
                                aligned_df[col] = None
                        existing_df = aligned_df
                    print(f"âš ï¸ æ ‡é¢˜è¡Œæ— æ•ˆï¼Œå°†ç¬¬ä¸€è¡Œå½“ä½œæ•°æ®è¯»å–: {len(existing_df)} è¡Œ")
        else:
            # Sheet ä¸ºç©ºï¼ˆæ–°sheetï¼‰
            print(f"â„¹ï¸ Sheet ä¸ºç©ºï¼ˆæ–°sheetï¼‰ï¼Œå°†åˆ›å»ºæ ‡é¢˜è¡Œ")
    except Exception as e:
        print(f"âš ï¸ è¯»å–ç°æœ‰æ•°æ®æ—¶å‡ºé”™: {e}ï¼Œå°†å½“ä½œæ–°sheetå¤„ç†")
    
    # ========== æ­¥éª¤4: åˆå¹¶æ•°æ®å¹¶å»é‡ ==========
    # ç¡®ä¿ existing_df å’Œ df çš„åˆ—é¡ºåºä¸€è‡´ï¼ˆåœ¨åˆå¹¶å‰ï¼‰
    if not existing_df.empty:
        # ç¡®ä¿ existing_df çš„åˆ—é¡ºåºä¸ expected_columns ä¸€è‡´
        if list(existing_df.columns) != expected_columns:
            # é‡æ–°æ’åˆ—åˆ—é¡ºåº
            missing_cols = [col for col in expected_columns if col not in existing_df.columns]
            if missing_cols:
                for col in missing_cols:
                    existing_df[col] = None
            existing_df = existing_df[expected_columns]
            print(f"âœ… å·²è°ƒæ•´ç°æœ‰æ•°æ®çš„åˆ—é¡ºåº")
        
        # ç¡®ä¿ df çš„åˆ—é¡ºåºä¹Ÿä¸€è‡´
        if list(df.columns) != expected_columns:
            missing_cols = [col for col in expected_columns if col not in df.columns]
            if missing_cols:
                for col in missing_cols:
                    df[col] = None
            df = df[expected_columns]
        
        # åˆå¹¶ç°æœ‰æ•°æ®å’Œæ–°æ•°æ®
        combined_df = pd.concat([existing_df, df], ignore_index=True)
        print(f"ğŸ“Š åˆå¹¶æ•°æ®: ç°æœ‰ {len(existing_df)} è¡Œ + æ–° {len(df)} è¡Œ = {len(combined_df)} è¡Œ")
    else:
        # ç¡®ä¿ df çš„åˆ—é¡ºåºä¸€è‡´
        if list(df.columns) != expected_columns:
            missing_cols = [col for col in expected_columns if col not in df.columns]
            if missing_cols:
                for col in missing_cols:
                    df[col] = None
            df = df[expected_columns]
        combined_df = df.copy()
    
    # å»é‡ï¼ˆåŸºäº URLï¼‰- å¿…é¡»æ‰§è¡Œï¼Œç¡®ä¿æ²¡æœ‰é‡å¤
    if 'URL' in combined_df.columns and not combined_df.empty:
        before_dedup = len(combined_df)
        # æ¸…ç† URL æ ¼å¼ï¼ˆå»é™¤ç©ºæ ¼ã€ç»Ÿä¸€æ ¼å¼ï¼‰
        combined_df['URL_cleaned'] = combined_df['URL'].astype(str).str.strip().str.lower()
        # å»é™¤ç©ºURL
        combined_df = combined_df[combined_df['URL_cleaned'] != '']
        combined_df = combined_df[combined_df['URL_cleaned'] != 'nan']
        # å»é‡ï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªï¼‰
        combined_df = combined_df.drop_duplicates(subset=['URL_cleaned'], keep='first')
        combined_df = combined_df.drop('URL_cleaned', axis=1)
        after_dedup = len(combined_df)
        if before_dedup > after_dedup:
            print(f"ğŸ“ URL å»é‡ï¼šç§»é™¤ {before_dedup - after_dedup} ç¯‡é‡å¤æ–‡ç« ï¼ˆåŸºäºURLï¼‰")
        else:
            print(f"âœ… URL å»é‡æ£€æŸ¥å®Œæˆï¼šæ— é‡å¤ï¼ˆ{after_dedup} è¡Œï¼‰")
    else:
        print(f"âš ï¸ è­¦å‘Šï¼šæ— æ³•è¿›è¡ŒURLå»é‡ï¼ˆURLåˆ—ä¸å­˜åœ¨æˆ–æ•°æ®ä¸ºç©ºï¼‰")
    
    # ========== æ­¥éª¤5: åªè¿½åŠ æ–°æ•°æ®ï¼Œä¸æ¸…ç©ºç°æœ‰æ•°æ®ï¼ˆå®Œå…¨å®‰å…¨ï¼‰ ==========
    if df.empty:
        print(f"â„¹ï¸ æ²¡æœ‰æ–°æ•°æ®å¯è¿½åŠ ")
        return
    
    # ç¡®ä¿æ–°æ•°æ®çš„åˆ—é¡ºåºä¸€è‡´
    df = df[expected_columns]
    
    # æ£€æŸ¥å¹¶ç¡®ä¿æ ‡é¢˜è¡Œå­˜åœ¨ï¼ˆåªæ£€æŸ¥ï¼Œä¸æ¸…ç©ºï¼‰
    try:
        existing_data = worksheet.get_all_values()
        has_header = False
        if len(existing_data) > 0:
            first_row = existing_data[0]
            first_row_set = set(str(c).strip() for c in first_row if c)
            expected_set = set(expected_columns)
            # å¦‚æœç¬¬ä¸€è¡ŒåŒ…å«è‡³å°‘3ä¸ªæœŸæœ›çš„åˆ—åï¼Œè®¤ä¸ºæ˜¯æ ‡é¢˜è¡Œ
            if len(first_row_set & expected_set) >= 3:
                has_header = True
        
        if not has_header:
            # æ²¡æœ‰æ ‡é¢˜è¡Œï¼Œåœ¨ç¬¬ä¸€è¡Œæ’å…¥æ ‡é¢˜è¡Œ
            print(f"âš ï¸ æ£€æµ‹åˆ°æ²¡æœ‰æ ‡é¢˜è¡Œï¼Œå°†åœ¨ç¬¬ä¸€è¡Œæ’å…¥æ ‡é¢˜è¡Œ")
            worksheet.insert_row(expected_columns, 1)
            print(f"âœ… å·²æ’å…¥æ ‡é¢˜è¡Œ: {expected_columns}")
        else:
            print(f"âœ… æ ‡é¢˜è¡Œå·²å­˜åœ¨")
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥æ ‡é¢˜è¡Œæ—¶å‡ºé”™: {e}ï¼Œå°è¯•æ’å…¥æ ‡é¢˜è¡Œ")
        try:
            existing_data = worksheet.get_all_values()
            if len(existing_data) == 0 or not any(str(c).strip() for c in existing_data[0] if existing_data):
                worksheet.insert_row(expected_columns, 1)
                print(f"âœ… å·²æ’å…¥æ ‡é¢˜è¡Œ")
        except:
            pass
    
    # åªè¿½åŠ æ–°æ•°æ®åˆ° sheet æœ«å°¾ï¼ˆå®Œå…¨ä¸æ¸…ç©ºï¼Œç»å¯¹å®‰å…¨ï¼‰
    batch_size = 100
    rows_written = 0
    for i in range(0, len(df), batch_size):
        batch = df.iloc[i:i+batch_size]
        values = batch.values.tolist()
        worksheet.append_rows(values)
        rows_written += len(batch)
    
    # æ£€æŸ¥å†™å…¥çš„æ•°æ®é‡
    if rows_written != len(df):
        print(f"âš ï¸ è­¦å‘Šï¼šå†™å…¥çš„æ•°æ®é‡ä¸åŒ¹é…ï¼æœŸæœ› {len(df)} è¡Œï¼Œå®é™…å†™å…¥ {rows_written} è¡Œ")
    
    print(f"âœ… å®Œæˆï¼å·²è¿½åŠ  {rows_written} è¡Œæ–°æ•°æ®åˆ° Google Sheets: {sheet_name}ï¼ˆä¸æ¸…ç©ºç°æœ‰æ•°æ®ï¼Œå®Œå…¨å®‰å…¨ï¼‰")
    print(f"â„¹ï¸ æ³¨æ„ï¼šå¦‚éœ€æ’åºï¼Œè¯·åœ¨ Google Sheets ä¸­æ‰‹åŠ¨æ’åºï¼Œæˆ–ä½¿ç”¨ reprocess_sheet.py è„šæœ¬")

def _sort_sheet_by_date(worksheet, df: pd.DataFrame, headers: list):
    """
    å¯¹ sheet æŒ‰æ—¥æœŸæ’åºï¼ˆè¾…åŠ©å‡½æ•°ï¼‰
    æ³¨æ„ï¼šæ­¤å‡½æ•°å·²å¼ƒç”¨ï¼Œä¸å†ä½¿ç”¨æ¸…ç©ºé‡å†™çš„æ–¹å¼ï¼Œé¿å…æ•°æ®ä¸¢å¤±
    å¦‚éœ€æ’åºï¼Œè¯·åœ¨ Google Sheets ä¸­æ‰‹åŠ¨æ’åºæˆ–ä½¿ç”¨å…¶ä»–å®‰å…¨æ–¹å¼
    """
    # å·²å¼ƒç”¨ï¼šä¸å†æ¸…ç©º sheet é‡æ–°å†™å…¥ï¼Œé¿å…æ•°æ®ä¸¢å¤±
    # å¦‚æœéœ€è¦æ’åºï¼Œè¯·åœ¨ Google Sheets ä¸­æ‰‹åŠ¨æ’åº
    print(f"âš ï¸ _sort_sheet_by_date å·²å¼ƒç”¨ï¼Œä¸å†æ‰§è¡Œæ’åºæ“ä½œï¼ˆé¿å…æ•°æ®ä¸¢å¤±ï¼‰")
    return

def create_weekly_sheet(df: pd.DataFrame, spreadsheet_id: str, 
                        credentials_path: str = "google_credentials.json"):
    """
    åˆ›å»ºæ¯å‘¨çš„ sheetï¼ˆæŒ‰æ—¥æœŸå‘½åï¼‰
    """
    # è·å–æ—¥æœŸèŒƒå›´
    if 'Date' in df.columns:
        dates = pd.to_datetime(df['Date'], errors='coerce').dropna()
        if len(dates) > 0:
            start_date = dates.min().strftime("%Y-%m-%d")
            end_date = dates.max().strftime("%Y-%m-%d")
            sheet_name = f"{start_date} to {end_date}"
        else:
            sheet_name = f"{datetime.now().strftime('%Y-%m-%d')}"
    else:
        sheet_name = f"Week {datetime.now().strftime('%Y-%m-%d')}"
    
    export_to_sheets(df, spreadsheet_id, sheet_name, credentials_path)

def read_from_sheets(spreadsheet_id: str, sheet_name: str = None,
                    credentials_path: str = None) -> pd.DataFrame:
    """
    ä» Google Sheets è¯»å–æ•°æ®
    """
    client = get_sheets_client(credentials_path)
    spreadsheet = client.open_by_key(spreadsheet_id)
    
    if sheet_name:
        worksheet = spreadsheet.worksheet(sheet_name)
    else:
        worksheet = spreadsheet.sheet1
    
    # è¯»å–æ‰€æœ‰æ•°æ®
    data = worksheet.get_all_values()
    
    if len(data) == 0:
        return pd.DataFrame()
    
    # ç¬¬ä¸€è¡Œä½œä¸ºåˆ—å
    df = pd.DataFrame(data[1:], columns=data[0])
    return df

