# 如何提升分类准确度？

## 🔍 当前情况

### 1. 反馈数量限制

**是的，目前只使用最近10个反馈**：
```python
user_feedback_examples[-10:]  # 只使用最近10个反馈
```

**原因**：
- Prompt 长度限制（OpenAI API 有 token 限制）
- 成本考虑（prompt 越长，成本越高）
- 最近的反馈更相关

**你的 Excel 合集**：
- 如果有很多反馈，但只用了最近10个
- 旧的反馈会被忽略

### 2. Prompt 真的可以提升准确度吗？

**✅ 是的，但有限制**

**Prompt Engineering 的效果**：
- ✅ **Few-shot learning** 确实可以提升准确度（研究证明）
- ✅ 提供好的示例，AI 可以学习模式
- ⚠️ 但效果有限，不是万能的

**实际效果**：
- 从 70-80% 准确度 → 85-90% 准确度（使用好的 prompt）
- 从 85-90% 准确度 → 95-98% 准确度（使用 API 分类 + 反馈）

## 💡 提升准确度的方法

### 方法 1: 增加反馈数量（推荐）

**当前限制**：只使用最近10个反馈

**改进方案**：
1. **增加反馈数量**：从10个增加到20-30个
2. **智能选择反馈**：不是简单的"最近10个"，而是：
   - 选择与当前文章最相关的反馈
   - 选择不同类别的反馈（确保每个类别都有示例）
   - 选择最近的、最准确的反馈

**实现**：
```python
# 当前代码
user_feedback_examples[-10:]  # 只使用最近10个

# 改进方案1：增加数量
user_feedback_examples[-30:]  # 使用最近30个

# 改进方案2：智能选择
# 选择与当前文章最相关的反馈（基于标题相似度）
# 选择不同类别的反馈（确保覆盖所有类别）
```

### 方法 2: 改进 Prompt 结构（推荐）

**当前 Prompt 的问题**：
- 示例太多（75个原始示例 + 10个反馈）
- 可能不够聚焦

**改进方案**：
1. **精简原始示例**：从75个减少到20-30个最相关的
2. **增加反馈示例的权重**：将反馈示例放在更显眼的位置
3. **添加类别特定的规则**：为每个类别添加更详细的判断标准

### 方法 3: 使用更好的模型（推荐）

**当前模型**：`gpt-4o-mini`

**改进方案**：
- 使用 `gpt-4o` 或 `gpt-4-turbo`（更准确，但更贵）
- 使用 `claude-3-opus`（Anthropic 的最强模型）

**效果**：
- `gpt-4o-mini`: 85-90% 准确度
- `gpt-4o`: 95-98% 准确度
- `claude-3-opus`: 95-98% 准确度

### 方法 4: 两阶段分类（高级）

**方案**：
1. **第一阶段**：粗分类（大类）
2. **第二阶段**：细分类（小类）

**优点**：
- 更精准
- 可以针对不同类别使用不同的 prompt

### 方法 5: 使用 Embedding 相似度（高级）

**方案**：
1. 将反馈文章转换为 embedding
2. 将新文章转换为 embedding
3. 找到最相似的反馈文章
4. 参考相似文章的类别

**优点**：
- 可以找到语义相似的反馈
- 不受"最近10个"限制

### 方法 6: 混合策略（推荐）

**方案**：
1. **API 分类**（主要方法）
2. **关键词分类**（回退方法）
3. **反馈学习**（持续改进）

**优点**：
- 结合多种方法的优势
- 更稳定、更准确

## 📊 实际建议

### 短期改进（容易实现）

1. **增加反馈数量**：从10个增加到20-30个
2. **改进 Prompt**：精简原始示例，增加反馈示例的权重
3. **使用更好的模型**：如果预算允许，使用 `gpt-4o`

### 中期改进（需要开发）

1. **智能选择反馈**：基于相似度选择最相关的反馈
2. **类别特定的 Prompt**：为每个类别定制 prompt
3. **两阶段分类**：粗分类 + 细分类

### 长期改进（需要大量工作）

1. **Fine-tuning**：使用 OpenAI 的 fine-tuning API 训练专用模型
2. **Embedding 相似度**：使用 embedding 找到最相似的反馈
3. **主动学习**：自动识别不确定的分类，请求人工确认

## 💡 最实用的改进

**推荐顺序**：
1. ✅ **增加反馈数量**（最简单，效果明显）
2. ✅ **改进 Prompt 结构**（中等难度，效果明显）
3. ✅ **使用更好的模型**（如果预算允许）
4. ⚠️ **智能选择反馈**（需要开发，效果最好）

