# Fine-tuning 详解

## 🤔 Fine-tuning 是什么？

**Fine-tuning** = 使用你自己的数据训练模型，让模型更适应你的特定任务

**简单理解**：
- 当前方法：每次分类时，通过 prompt 告诉模型如何分类（上下文学习）
- Fine-tuning：用你的数据训练模型，模型"记住"了如何分类（真正的学习）

## 📊 Fine-tuning vs Prompt Engineering

### 当前方法（Prompt Engineering）

**方式**：
- 使用预训练模型（gpt-4o-mini）
- 每次分类时，通过 prompt 提供示例和规则
- 模型根据 prompt 进行分类

**特点**：
- ✅ 不需要训练数据
- ✅ 可以随时修改 prompt
- ✅ 成本低（每次调用 $0.0003）
- ❌ 每次都要发送完整的 prompt
- ❌ 受 prompt 长度限制（只能使用最近10个反馈）
- ❌ AI 没有"记忆"，每次都是独立的

**准确度**：85-95%

### Fine-tuning 方法

**方式**：
- 准备训练数据（至少几百条，格式：文章 → 类别）
- 上传到 OpenAI，训练自定义模型
- 使用训练好的模型进行分类

**特点**：
- ✅ 模型"记住"了你的分类规则
- ✅ 不需要每次都发送完整的 prompt
- ✅ 不受 prompt 长度限制（可以使用所有训练数据）
- ✅ 准确度更高（95-98%）
- ❌ 需要准备大量训练数据（至少几百条）
- ❌ 需要训练成本（$8-80，取决于数据量）
- ❌ 训练需要时间（几小时到几天）
- ❌ 修改规则需要重新训练

**准确度**：95-98%

## 🔄 Fine-tuning 的工作机制

### 1. 准备训练数据

**格式**：JSONL 文件（每行一个训练样本）

```json
{"messages": [
  {"role": "system", "content": "你是一个专业的新闻分类助手。"},
  {"role": "user", "content": "China rolls out red carpet as Thailand's king makes first official visit\n\n这是中国接待外国领导人的国事访问..."},
  {"role": "assistant", "content": "US Multilateralism"}
]}
{"messages": [
  {"role": "system", "content": "你是一个专业的新闻分类助手。"},
  {"role": "user", "content": "Tencent AI launches new chatbot\n\n腾讯AI发布新聊天机器人..."},
  {"role": "assistant", "content": "Uncategorized"}
]}
...
```

**需要多少数据**：
- 最少：100-200 条
- 推荐：500-1000 条
- 最佳：2000+ 条

### 2. 上传并训练

**步骤**：
1. 准备 JSONL 文件
2. 上传到 OpenAI
3. 创建 Fine-tuning Job
4. 等待训练完成（几小时到几天）

**成本**：
- 训练成本：$8-80（取决于数据量和模型）
- 使用成本：与基础模型相同或略高

### 3. 使用训练好的模型

**方式**：
```python
# 使用 fine-tuned 模型
response = client.chat.completions.create(
    model="ft:gpt-4o-mini:your-org:custom-model:xxxxx",  # 你的自定义模型
    messages=[
        {"role": "system", "content": "你是一个专业的新闻分类助手。"},
        {"role": "user", "content": "文章标题和摘要"}
    ]
)
```

**特点**：
- Prompt 可以非常简短（不需要大量示例）
- 模型已经"学会"了你的分类规则
- 准确度更高

## 💡 Fine-tuning vs Prompt Engineering 对比

| 特性 | Prompt Engineering（当前） | Fine-tuning |
|------|---------------------------|-------------|
| **准确度** | 85-95% | 95-98% |
| **训练数据** | 不需要 | 需要（至少几百条） |
| **训练成本** | 无 | $8-80 |
| **训练时间** | 无 | 几小时到几天 |
| **修改规则** | 随时修改 prompt | 需要重新训练 |
| **Prompt 长度** | 受限制（只能10个反馈） | 不受限制 |
| **模型记忆** | 无（每次独立） | 有（真正学习） |
| **使用成本** | $0.0003/次 | $0.0003-0.001/次 |
| **适用场景** | 快速迭代、规则变化频繁 | 规则稳定、需要高准确度 |

## 🎯 什么时候用 Fine-tuning？

### 适合 Fine-tuning 的情况

1. **有大量训练数据**（至少500条）
2. **分类规则相对稳定**（不会频繁变化）
3. **需要高准确度**（95%+）
4. **有预算**（训练成本 + 使用成本）
5. **可以等待训练时间**（几小时到几天）

### 不适合 Fine-tuning 的情况

1. **训练数据不足**（少于200条）
2. **分类规则经常变化**
3. **需要快速迭代**
4. **预算有限**
5. **需要立即使用**

## 💡 实际建议

### 当前情况

**你的情况**：
- 有反馈数据（但可能不够500条）
- 分类规则可能还在调整
- 需要快速迭代

**建议**：
- ✅ **继续使用 Prompt Engineering**（当前方法）
- ✅ **增加反馈数量**（从10个增加到20-30个）
- ✅ **添加"原因"字段**（让反馈更有价值）
- ⚠️ **暂时不考虑 Fine-tuning**（除非有大量训练数据且规则稳定）

### 未来考虑 Fine-tuning

**如果满足以下条件，可以考虑 Fine-tuning**：
1. 积累了至少 500 条高质量的反馈数据
2. 分类规则已经稳定（不会频繁变化）
3. 需要更高的准确度（95%+）
4. 有预算和时间

**Fine-tuning 的优势**：
- ✅ 可以使用所有训练数据（不受"10个"限制）
- ✅ 模型真正"学会"了分类规则
- ✅ 准确度更高
- ✅ Prompt 可以更简短

## 📝 总结

**Fine-tuning**：
- 使用你的数据训练模型
- 模型"记住"了分类规则
- 准确度更高（95-98%）
- 但需要大量训练数据、成本和时间

**当前方法（Prompt Engineering）**：
- 通过 prompt 指导分类
- 不需要训练数据
- 可以随时修改
- 准确度稍低（85-95%）

**建议**：
- 当前继续使用 Prompt Engineering
- 积累更多反馈数据
- 如果规则稳定且有足够数据，再考虑 Fine-tuning

