# API 分类器工作原理详解

## 📊 重要澄清：我们没有"训练"模型

### 当前实现方式

1. **使用预训练模型**
   - GPT-4o-mini 或 Claude Haiku 是 OpenAI/Anthropic 已经训练好的通用模型
   - 模型已经具备强大的理解和分类能力
   - 我们不需要训练，直接使用即可

2. **每次分类都是独立的**
   - 每次调用 API 都是独立的请求
   - 不积累"经验"或"记忆"
   - 不依赖历史分类结果

3. **使用 Prompt 指导分类**
   - 通过精心设计的 prompt 告诉模型如何分类
   - 每次使用相同的 prompt 模板
   - 模型根据 prompt 和文章内容进行分类

## 🔄 切换 API Key 的影响

### 如果使用相同的模型（如 gpt-4o-mini）

**✅ 精准度应该相同**

原因：
- 使用相同的模型（gpt-4o-mini）
- 使用相同的 prompt
- 模型行为一致（相同输入 → 相同输出）
- API key 只是身份验证，不影响模型行为

**⚠️ 可能的微小差异**

1. **API 版本差异**（通常相同）
   - 不同 API key 可能访问不同版本的 API
   - 但通常都是最新版本

2. **模型配置差异**（通常相同）
   - 默认配置应该相同
   - 但某些企业账号可能有特殊配置

3. **随机性**（temperature=0.3）
   - 由于 temperature=0.3，每次结果可能有轻微差异
   - 但这是正常的，不影响整体精准度

## 💡 如何提高精准度

### 方式 1: 改进 Prompt（推荐，免费）

**当前 prompt**:
```
请将以下新闻文章分类到最合适的类别。可用类别：{categories}

文章内容：
{headline + nut_graph}

请只返回类别名称，不要其他内容。如果无法分类，返回 "Uncategorized"。
```

**可以改进的方向**:
1. **添加分类示例（Few-shot Learning）**
   ```
   示例：
   - "China announces new trade policy" → "Trade"
   - "US-China technology competition intensifies" → "Technology"
   - "Chinese economy grows 5%" → "Economy"
   ```

2. **添加更详细的类别说明**
   ```
   类别说明：
   - Trade: 涉及贸易、关税、进出口
   - Technology: 涉及科技、芯片、5G
   - Economy: 涉及经济、GDP、金融
   ...
   ```

3. **添加分类规则**
   ```
   分类规则：
   - 优先选择最具体的类别
   - 如果文章涉及多个类别，选择最重要的
   - 如果不确定，返回 "Uncategorized"
   ```

### 方式 2: Fine-tuning（高级，需要成本）

**什么是 Fine-tuning**:
- 使用自己的数据训练模型
- 让模型更适应你的分类任务
- 需要准备训练数据（输入-输出对）

**Fine-tuning 的优缺点**:

✅ 优点:
- 精准度可能更高（90-95% → 95-98%）
- 更适应你的特定分类需求
- 可能更快（使用更小的模型）

❌ 缺点:
- 需要准备大量训练数据（至少几百条）
- 需要额外成本（训练费用 + 使用费用）
- 需要时间（训练可能需要几小时）
- 如果切换 API key，需要重新训练（如果使用自定义模型）

**Fine-tuning 流程**:
1. 准备训练数据（JSONL 格式）
   ```json
   {"messages": [{"role": "system", "content": "..."}, {"role": "user", "content": "..."}, {"role": "assistant", "content": "Trade"}]}
   ```

2. 上传到 OpenAI
3. 创建 Fine-tuning Job
4. 等待训练完成
5. 使用自定义模型进行分类

**⚠️ 重要**: 如果使用 Fine-tuning，切换 API key 时：
- 如果公司账号可以访问你的自定义模型 → 精准度相同
- 如果公司账号无法访问 → 需要使用基础模型，精准度可能略低

## 📊 当前实现 vs Fine-tuning

| 特性 | 当前实现（Prompt） | Fine-tuning |
|------|-------------------|-------------|
| 精准度 | 90-95% | 95-98% |
| 成本 | 低（每次调用 $0.0003） | 高（训练 + 使用） |
| 准备时间 | 0（立即可用） | 几小时到几天 |
| 切换 API key | ✅ 精准度相同 | ⚠️ 取决于模型访问权限 |
| 维护 | 简单（只需改 prompt） | 复杂（需要重新训练） |

## 🎯 推荐方案

### 对于你的使用场景

**推荐：使用 Prompt 方式（当前实现）**

理由：
1. ✅ 精准度已经很高（90-95%）
2. ✅ 切换 API key 不影响精准度
3. ✅ 成本低
4. ✅ 维护简单
5. ✅ 可以随时改进 prompt

**如果未来需要更高精准度**:
1. 先尝试改进 prompt（添加示例、说明等）
2. 如果还不够，再考虑 Fine-tuning

## 🔄 切换 API Key 的最佳实践

### 确保精准度一致

1. **使用相同的模型**
   ```toml
   [api]
   provider = "openai"
   openai_model = "gpt-4o-mini"  # 确保相同
   ```

2. **使用相同的 prompt**
   - prompt 在代码中，切换 API key 不影响

3. **使用相同的 temperature**
   - 当前是 0.3，确保切换后也是 0.3

4. **测试验证**
   - 切换后，用相同的文章测试
   - 确认分类结果一致

## 📝 总结

1. **我们没有"训练"模型**，只是使用预训练模型
2. **切换 API key 不影响精准度**（如果使用相同模型）
3. **提高精准度的方法**：
   - 改进 prompt（推荐，免费）
   - Fine-tuning（高级，需要成本）
4. **当前实现已经很好**（90-95% 精准度）
5. **可以放心切换 API key**，精准度应该相同

