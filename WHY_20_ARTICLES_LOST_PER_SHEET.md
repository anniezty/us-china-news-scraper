# 为什么每个 Sheet 都丢失了 20+ 篇文章？

## 🤔 你的问题

1. **边界情况什么意思？**
2. **其他都没有改变，为什么就会这样？**
3. **而且是丢失了20多个每个sheet，是因为什么丢失了的呢？**

## 📝 解释

### 1. 什么是"边界情况"？

**边界情况** = 代码没有考虑到的情况，或者很少发生但会导致问题的情况

**例子**：
- 空白 sheet（代码可能没有考虑到）
- 列名不匹配（代码可能没有考虑到）
- 数据格式异常（代码可能没有考虑到）
- 空值或特殊字符（代码可能没有考虑到）

**为什么叫"边界"**：
- 就像走在边界线上，一不小心就会出问题
- 代码在正常情况（中间）工作正常，但在边界情况（边缘）可能出错

### 2. 为什么"其他都没有改变"还会出问题？

**可能的原因**：

#### 原因 A: 空白 Sheet 触发了隐藏的 Bug

**之前的代码逻辑**（可能有问题）：
```python
# 读取所有 sheet 的 URL（用于跨 sheet 去重）
for sheet in spreadsheet.worksheets():
    # 如果空白 sheet 导致读取错误
    # 或者空白 sheet 的格式特殊
    # 可能导致 all_existing_urls 或 current_sheet_urls 不正确
```

**如果空白 sheet 导致读取错误**：
- `all_existing_urls` 可能不完整
- `current_sheet_urls` 可能不完整
- 导致去重逻辑出错

#### 原因 B: 去重逻辑的 Bug

**看代码第 236-243 行**：
```python
combined_df = pd.concat([existing_df, df], ignore_index=True)
# 在当前 sheet 内去重（清理 existing_df 本身可能存在的重复）
combined_df = combined_df.drop_duplicates(subset=['URL'], keep='first')
```

**问题**：如果 `existing_df` 本身有重复，去重后会减少。但这是正常的。

**但如果去重逻辑有问题**：
- 可能误删了不重复的文章
- 或者 URL 格式不一致导致误判为重复

#### 原因 C: 列对齐时的数据丢失

**如果空白 sheet 导致列对齐出错**：
- `existing_df` 在列对齐时可能丢失数据
- 但之前的代码可能没有检查
- 导致丢失的数据被写入

### 3. 为什么每个 Sheet 都丢失了 20+ 篇？

**可能的原因**：

#### 假设 1: 每个 Sheet 都有 20+ 篇重复文章

**如果之前的代码没有去重**：
- 每个 sheet 可能积累了 20+ 篇重复文章
- 现在代码去重后，每个 sheet 减少了 20+ 篇
- **这不是丢失，而是清理重复**

**检查方法**：看看日志中是否有 "📝 Sheet 内去重：移除 X 篇重复文章"

#### 假设 2: 去重逻辑误删了数据

**如果 URL 格式不一致**：
- 例如：有些 URL 有尾随空格，有些没有
- `drop_duplicates()` 可能误判为不同 URL
- 但实际上应该是同一个

**或者**：
- 如果 URL 列有缺失值（None）
- `drop_duplicates()` 可能误删数据

#### 假设 3: 列对齐时丢失了数据

**如果列对齐出错**：
- `existing_df` 在列对齐时丢失了 20+ 行
- 但之前的代码没有检查
- 导致丢失的数据被写入

## 🔍 如何确认原因？

### 检查日志

查看运行日志，看看是否有：
1. `"📝 Sheet 内去重：移除 X 篇重复文章"` - 如果是这个，说明是清理重复，不是丢失
2. `"⚠️ 列名不匹配"` - 如果是这个，说明列对齐可能有问题
3. `"❌ 错误：列对齐导致数据丢失"` - 如果是这个，说明列对齐确实丢失了数据

### 检查 Google Sheets 版本历史

1. 打开 Google Sheets
2. File → Version history
3. 查看数据丢失前的版本
4. 对比数据，看看丢失的是哪些文章

## ✅ 现在的保护措施

**无论原因是什么，现在的代码都有保护措施**：

1. ✅ 列对齐后检查行数（第 216-218 行）
2. ✅ 数据处理后检查行数（第 224-226 行）
3. ✅ 合并前检查数据量（第 307-310 行）

**如果检测到数据丢失，会停止操作，不清空 sheet**

## 💡 建议

1. **检查日志**：查看是否有 "📝 Sheet 内去重" 或 "❌ 错误" 信息
2. **检查版本历史**：看看丢失的是哪些文章，是否是重复的
3. **如果确实是丢失**：检查日志中的错误信息，找出原因

## 📝 总结

**"边界情况"** = 代码没有考虑到的情况（如空白 sheet）

**为什么"其他都没有改变"还会出问题**：
- 空白 sheet 可能触发了隐藏的 bug
- 或者之前的代码逻辑本身有问题

**为什么每个 Sheet 都丢失了 20+ 篇**：
- 可能是清理重复（正常）
- 可能是去重逻辑误删（bug）
- 可能是列对齐丢失（bug）

**现在的保护措施**：
- ✅ 会检测数据丢失
- ✅ 会停止操作，不清空 sheet
- ✅ 不会再发生类似问题

