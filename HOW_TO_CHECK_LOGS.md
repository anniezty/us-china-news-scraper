# 如何检查日志中的错误信息

## 📁 日志文件位置

### 1. 定时任务日志
- **文件路径**：`logs/daily_collector.log`
- **内容**：每天定时收集任务的日志
- **包含**：数据收集、上传到 Google Sheets 的过程

### 2. 优先级收集日志
- **文件路径**：`logs/priority_collector.log`
- **内容**：优先级来源的收集日志

## 🔍 如何查看日志

### 方法 1: 使用命令行（推荐）

```bash
# 查看最后 100 行日志
tail -100 logs/daily_collector.log

# 查看最后 50 行日志（实时更新）
tail -f logs/daily_collector.log

# 搜索错误信息
grep -i "错误\|error\|❌" logs/daily_collector.log

# 搜索警告信息
grep -i "警告\|warning\|⚠️" logs/daily_collector.log

# 搜索去重信息
grep -i "去重\|dedup" logs/daily_collector.log

# 搜索列对齐信息
grep -i "列名\|column\|对齐" logs/daily_collector.log
```

### 方法 2: 在 Cursor IDE 中查看

1. 打开 `logs/daily_collector.log` 文件
2. 使用搜索功能（Cmd/Ctrl + F）搜索关键词
3. 查看最近的日志条目

### 方法 3: 使用终端命令查看特定信息

```bash
# 查看所有错误
grep "❌" logs/daily_collector.log

# 查看所有警告
grep "⚠️" logs/daily_collector.log

# 查看去重信息
grep "📝" logs/daily_collector.log

# 查看数据丢失相关的信息
grep -i "丢失\|减少\|数据量" logs/daily_collector.log
```

## 🔎 需要查找的关键信息

### 1. 数据丢失相关的错误

**查找关键词**：
- `❌ 错误：列对齐导致数据丢失`
- `❌ 错误：数据处理后行数不匹配`
- `❌ 错误：合并后数据量减少`

**如果看到这些**：
- 说明检测到数据丢失
- 操作已停止，sheet 没有被清空
- 需要检查列格式问题

### 2. 列对齐相关的警告

**查找关键词**：
- `⚠️ 列名不匹配`
- `⚠️ 警告：列对齐后行数变化`
- `⚠️ 警告：读取的数据行数不匹配`

**如果看到这些**：
- 说明列格式可能有问题
- 需要检查现有数据的列格式

### 3. 去重信息

**查找关键词**：
- `📝 跨 sheet 去重：过滤掉 X 篇已存在的文章`
- `📝 当前 sheet 去重：过滤掉 X 篇已存在的文章`
- `📝 Sheet 内去重：移除 X 篇重复文章`

**如果看到这些**：
- 说明是正常的去重操作
- 不是数据丢失，而是清理重复

### 4. 成功信息

**查找关键词**：
- `✅ 已追加 X 行新数据，总计 Y 行`
- `✅ 已按日期排序完成`
- `✅ 成功上传 X 篇文章到 Google Sheets`

**如果看到这些**：
- 说明操作成功
- 数据已正确写入

## 📊 日志示例

### 正常情况（没有错误）

```
[2025-11-13 10:00:00] 开始抓取 2025-11-13 的文章...
[2025-11-13 10:00:05] 找到 25 篇文章
[2025-11-13 10:00:10] 正在上传到 Google Sheets: Week 2025-11-10 to 2025-11-17...
📝 跨 sheet 去重：过滤掉 5 篇已存在的文章（其他 sheet 中）
📝 当前 sheet 去重：过滤掉 3 篇已存在的文章（当前 sheet 中）
📝 Sheet 内去重：移除 2 篇重复文章（清理现有数据中的重复）
✅ 已追加 17 行新数据，总计 420 行（已按日期排序）到 Google Sheets: Week 2025-11-10 to 2025-11-17
[2025-11-13 10:00:15] ✅ 成功上传 17 篇文章到 Google Sheets
```

### 异常情况（有错误）

```
[2025-11-13 10:00:00] 开始抓取 2025-11-13 的文章...
[2025-11-13 10:00:05] 找到 25 篇文章
[2025-11-13 10:00:10] 正在上传到 Google Sheets: Week 2025-11-10 to 2025-11-17...
⚠️ 列名不匹配！现有列: ['URL', 'Date', 'Headline'], 期望列: ['Nested?', 'URL', 'Date', 'Outlet', 'Headline', 'Nut Graph']
⚠️ 警告：列对齐后行数变化！对齐前 400 行，对齐后 380 行
❌ 错误：列对齐导致数据丢失！停止操作，不清空 sheet
[2025-11-13 10:00:15] ❌ 上传失败: 列对齐导致数据丢失：400 行 -> 380 行
```

## 💡 如何理解日志信息

### 如果看到 "📝 Sheet 内去重：移除 X 篇重复文章"

**含义**：
- 这是正常的去重操作
- 不是数据丢失，而是清理重复
- 如果每个 sheet 都减少了 20+ 篇，说明之前确实有重复

**行动**：
- ✅ 这是正常的，不需要担心
- ✅ 数据是安全的，只是清理了重复

### 如果看到 "❌ 错误：列对齐导致数据丢失"

**含义**：
- 检测到数据丢失
- 操作已停止，sheet 没有被清空
- 数据是安全的

**行动**：
- ⚠️ 需要检查列格式问题
- ⚠️ 检查现有数据的列名是否与代码一致
- ⚠️ 可能需要手动修复列格式

### 如果看到 "⚠️ 列名不匹配"

**含义**：
- 现有数据的列名与新数据的列名不一致
- 代码会尝试对齐，但需要检查

**行动**：
- ⚠️ 检查现有数据的列格式
- ⚠️ 确保列名与代码一致

## 🔧 快速检查命令

```bash
# 进入项目目录
cd /Users/tingyuzheng/Projects/us_china_picker

# 查看最近的日志（最后 50 行）
tail -50 logs/daily_collector.log

# 搜索所有错误
grep "❌" logs/daily_collector.log | tail -20

# 搜索所有警告
grep "⚠️" logs/daily_collector.log | tail -20

# 搜索去重信息
grep "📝.*去重" logs/daily_collector.log | tail -20

# 搜索数据丢失相关信息
grep -i "丢失\|减少\|数据量\|行数" logs/daily_collector.log | tail -20
```

## 📝 总结

**日志文件位置**：
- `logs/daily_collector.log` - 定时任务日志

**关键信息**：
- `❌` - 错误（需要关注）
- `⚠️` - 警告（需要检查）
- `📝` - 信息（通常是正常的）
- `✅` - 成功（正常）

**如果看到错误**：
- 检查错误信息的具体内容
- 根据错误信息采取相应的行动
- 现在的保护措施会阻止数据丢失

